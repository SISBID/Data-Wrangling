---
title: "Data Cleaning lab"
output: html_document
---

```{r}
library(tidyverse)
```


1. Read in the UFO dataset (used in the Data IO lectures) as an R object called `ufo`.
You can read directly from the web here: https://raw.githubusercontent.com/SISBID/Module1/gh-pages/data/ufo/ufo_data_complete.csv . 
You can ignore the "problems" with some rows. 

```{r}

```

2. Clean up the column/variable names of the `ufo` dataset to remove spaces and non-alphanumeric characters. You can use the `dplyr::rename()` function or look into the `janitor::clean_names()` function. Save the data as `uf_clean`.

```{r}

```

3. Filter for rows where state is "tx" or  "nm", "ut". Then use `recode` to make an exact swap of "Texas" for "tx" and "New_Mexico" for "nm" and "Utah" for "ut" of the `state` variable. Save the output as `South_West`. hint- you will need `mutate`.

```{r}

```

4. Use `case_when()` on the ufo data to create a new variable about continent. If the country is "ca" or "us" make the value be "North America", if it is "gb" or "de" make the value "Europe", and if it is "au" make it "Australia". No need to worry about the `TRUE` statement as we want to keep our other `NA` values.

```{r}

```
