---
title: "Advanced Data IO"
author: "Data Wrangling in R"
output:
  ioslides_presentation:
    css: styles.css
    widescreen: yes
---

```{r, echo = FALSE, include=FALSE, purl=FALSE}
library(knitr)
opts_chunk$set(comment = "")
```

```{r, include=FALSE}
library(tidyverse)
library(rvest)
library(jsonlite)
```

# Google Sheets

---

```{r, out.width="100%", echo = FALSE, purl=FALSE}
knitr::include_graphics("media/AdvancedIO_googlesheet.png")
```

https://docs.google.com/spreadsheets/d/1U6Cf_qEOhiR9AZqTqS3mbMF3zt2db48ZP5v3rkrAEJY/edit#gid=780868077

## Reading data with the googlesheets4 package

First, set up Google credentials

```{r}
library(googlesheets4)
```
```{r eval=FALSE}
# Prompts a browser pop-up
gs4_auth()
```
```{r}
# Once set up, you can automate this process by passing your email
gs4_auth(email = "avamariehoffman@gmail.com")
```

## Reading data with the googlesheets4 package

You can also supply an authorization token directly, but make sure to add any files to your .gitignore!

```{r eval = FALSE}
library(googledrive)
drive_auth(email= "<email>",
           token = readRDS("google-sheets-token.rds")) # Saved in a file
```

## Reading data with the googlesheets4 package

Read in using `googlesheets4::read_sheet`

```{r}
sheet_url = paste0("https://docs.google.com/spreadsheets/d/1U6Cf_qEOhiR9",
                   "AZqTqS3mbMF3zt2db48ZP5v3rkrAEJY/edit#gid=780868077")
sheet_dat_1 = read_sheet(sheet_url)
head(sheet_dat_1)
```

## Reading data with the googlesheets4 package

Specify the sheet name if necessary:

```{r}
sheet_url = paste0("https://docs.google.com/spreadsheets/d/1U6Cf_qEOhiR9",
                   "AZqTqS3mbMF3zt2db48ZP5v3rkrAEJY/edit#gid=780868077")
sheet_dat_oceania = read_sheet(sheet_url, sheet = "Oceania")
head(sheet_dat_oceania)
```

## Reading data with the googlesheets4 package

Alternatively, list out the sheet names using `sheet_names()`.

```{r}
sheet_names(sheet_url)
```

## Reading data with the googlesheets4 package

Iterate through the sheet names:

```{r}
gapminder_sheets = sheet_names(sheet_url)

data_list = list()
for(g_sheet in gapminder_sheets){
  data_list[[g_sheet]] = read_sheet(sheet_url, sheet = g_sheet)
}
str(data_list)
```

## Reading data with the googlesheets4 package

Iterate through the sheet names:

```{r}
str(data_list)
```

## Writing data with the googlesheets4 package

```{r}
sheet_dat_oceania = sheet_dat_oceania %>%
  mutate(lifeExp_days = lifeExp * 365)
sheet_out = gs4_create("Oceania-days", 
                       sheets = list(Oceania_days = sheet_dat_oceania))
```
```{r eval = FALSE}
# Opens a browser window
gs4_browse(sheet_out)
```

## Append data with the googlesheets4 package

```{r}
sheet_append(sheet_out, data = sheet_dat_oceania, sheet = "Oceania_days")
```

## JHU Tidyverse Book

https://jhudatascience.org/tidyversecourse/get-data.html#google-sheets

# googlesheets Lab<br> http://sisbid.github.io/Data-Wrangling/labs/advanced-io-lab.Rmd

# JSON: JavaScript Object Notation<br>Lists of stuff

---

```{r, out.width="80%", echo = FALSE, purl=FALSE}
knitr::include_graphics("wiki_json.png")
```

https://en.wikipedia.org/wiki/JSON

## Why JSON matters

```{r, out.width="80%", echo = FALSE, purl=FALSE}
knitr::include_graphics("github_json.png")
```

https://docs.github.com/en/rest/reference/search

---

```{r}
#install.packages("jsonlite")
library(jsonlite)
jsonData <- fromJSON("https://raw.githubusercontent.com/Biuni/PokemonGO-Pokedex/master/pokedex.json")
head(jsonData)
```

## Data frame structure from JSON

```{r}
dim(jsonData$pokemon)
class(jsonData$pokemon$type) # Can be lists
jsonData$pokemon$type
```

## Data frame structure from JSON

```{r}
class(jsonData$pokemon$next_evolution[[1]]) # Or lists of data.frames!
jsonData$pokemon$next_evolution
```

# JSON Lab<br> http://sisbid.github.io/Data-Wrangling/labs/advanced-io-lab.Rmd

# Web Scraping

## This is data

http://bowtie-bio.sourceforge.net/recount/ 
```{r, out.width="100%", echo = FALSE, purl=FALSE}
knitr::include_graphics("recount.png")
```

## View the source

```{r, out.width="100%", echo = FALSE, purl=FALSE}
knitr::include_graphics("recount_view.png")
```

## What the computer sees

```{r, out.width="100%", echo = FALSE, purl=FALSE}
knitr::include_graphics("recount_source.png")
```

## Ways to see the source

<div class="left-half">
<div style="font-size:15pt">
Chrome:

1. right click on page
2. select "view source"

Firefox:

1. right click on page
2. select "view source"

Microsoft Edge:

1. right click on page
2. select "view source"
</div>
</div>

<div class="right-half">

Safari

1. click on "Safari"
2. select "Preferences"
3. go to "Advanced"
4. check "Show Develop menu in menu bar"
5. click on "Develop"
6. select "show page source"
7. alternatively to 5./6., right click on page and select "view source"
</div>

https://github.com/simonmunzert/rscraping-jsm-2016/blob/c04fd91fec711df65c838e07723125155a7f2cda/02-scraping-with-rvest.r

## Inspect element

```{r, out.width="100%", echo = FALSE, purl=FALSE}
knitr::include_graphics("recount_inpsect.png")
```

## Copy XPath

```{r, out.width="100%", echo = FALSE, purl=FALSE}
knitr::include_graphics("recount_xpath.png")
```

## Use SelectorGadget

https://cran.r-project.org/web/packages/rvest/vignettes/selectorgadget.html



## rvest package
```{r}
recount_url = "http://bowtie-bio.sourceforge.net/recount/"
# install.packages("rvest")
library(rvest)
htmlfile = read_html(recount_url)

nds = html_nodes(htmlfile,                
xpath='//*[@id="recounttab"]/table')
dat = html_table(nds)
dat = as.data.frame(dat)
head(dat)
```

## Little cleanup

```{r}
colnames(dat) = as.character(dat[1,])
dat = dat[-1,]
head(dat)
```


----

http://motherboard.vice.com/read/70000-okcupid-users-just-had-their-data-published
```{r, out.width="100%", echo = FALSE, purl=FALSE}
knitr::include_graphics("okcupid.png")
```

----
https://www.theguardian.com/science/2012/may/23/text-mining-research-tool-forbidden
```{r, out.width="100%", echo = FALSE, purl=FALSE}
knitr::include_graphics("textmining.png")
```

# APIs

## Application Programming Interfaces
https://developers.facebook.com/
```{r, out.width="100%", echo = FALSE, purl=FALSE}
knitr::include_graphics("facebook_dev.png")
```

## In biology too!
http://www.ncbi.nlm.nih.gov/books/NBK25501/

```{r, out.width="100%", echo = FALSE, purl=FALSE}
knitr::include_graphics("nih_api.png")
```

## Step 0: Did someone do this already
https://ropensci.org/packages/

```{r, out.width="100%", echo = FALSE, purl=FALSE}
knitr::include_graphics("ropensci.png")
```

## Do it yourself: read the Docs

https://docs.github.com/en/rest
```{r, out.width="100%", echo = FALSE, purl=FALSE}
knitr::include_graphics("github_rest.png")
```


## Read the docs
https://docs.github.com/en/rest/reference/repos

```{r, out.width="100%", echo = FALSE, purl=FALSE}
knitr::include_graphics("github_repo.png")
```

## Read the docs
https://docs.github.com/en/rest/reference/rate-limit

```{r, out.width="100%", echo = FALSE, purl=FALSE}
knitr::include_graphics("github_ratelimit.png")
```

## Read the docs

```{r, out.width="100%", echo = FALSE, purl=FALSE}
knitr::include_graphics("github_jquery.png")
```

## A dissected example

<div style="font-size:30pt">
https://api.github.com/search/repositories?q=created:2014-08-13+language:r+-user:cran
</div>

## The base URL
<div style="font-size:30pt">
**https://api.github.com/**search/repositories?q=created:2014-08-13+language:r+-user:cran
</div>

## The Path: Search repositories
<div style="font-size:30pt">
https://api.github.com/**search/repositories**?q=created:2014-08-13+language:r+-user:cran
</div>

## Create a query - pass the `q` parameter
<div style="font-size:30pt">
https://api.github.com/search/repositories**?q**=created:2014-08-13+language:r+-user:cran
</div>

## Date repo was created
<div style="font-size:30pt">
https://api.github.com/search/repositories?q=**created:2014-08-13**+language:r+-user:cran
</div>

## Language repo is in
<div style="font-size:30pt">
https://api.github.com/search/repositories?q=created:2014-08-13+**language:r**+-user:cran
</div>

## Ignore repos from "cran"
<div style="font-size:30pt">
https://api.github.com/search/repositories?q=created:2014-08-13+language:r+**-user:cran**
</div>

----
```{r}
#install.packages("httr")
library(httr)

query_url = paste0("https://api.github.com/", "search/repositories", 
                   "?q=created:2014-08-13", "+language:r", "+-user:cran")

req = GET(query_url)
names(content(req))
```

## Not all APIs are "open"

https://apps.twitter.com/

```{r, out.width="100%", echo = FALSE, purl=FALSE}
knitr::include_graphics("twitter.png")
```

---

(see also `twitteR` package)

```{r, eval = FALSE}
myapp = oauth_app("twitter",
                   key="yourConsumerKeyHere",secret="yourConsumerSecretHere")
sig = sign_oauth1.0(myapp,
                     token = "yourTokenHere",
                      token_secret = "yourTokenSecretHere")
homeTL = GET("https://api.twitter.com/1.1/statuses/home_timeline.json", sig)

# But you can get cool data
json1 = content(homeTL)
json2 = jsonlite::fromJSON(toJSON(json1))
json2[1,1:4]
```

```{r, eval = FALSE}
                    created_at           id             id_str
1 Mon Jan 13 05:18:04 +0000 2014 4.225984e+17 422598398940684288
                                                                                                                                         text
1 Now that P. Norvig's regex golf IPython notebook hit Slashdot, let's see if our traffic spike tops the previous one: http://t.co/Vc6JhZXOo8
```

