---
title: "Data Cleaning Part 1"
author: "Data Wrangling in R"
output:
  ioslides_presentation:
    css: styles.css
    widescreen: yes
  beamer_presentation: default
---


```{r, include = FALSE}
library(knitr)
library(tidyverse)
library(janitor)
opts_chunk$set(comment = "")
```

## Data Cleaning

In general, data cleaning is a process of investigating your data for inaccuracies, or recoding it in a way that makes it more manageable.

MOST IMPORTANT RULE - LOOK AT YOUR DATA!



## Read in the UFO dataset

Read in data or download from: http://sisbid.github.io/Data-Wrangling/data/ufo/ufo_data_complete.csv.gz

```{r}
ufo <- read_delim("https://sisbid.github.io/Data-Wrangling/data/ufo/ufo_data_complete.csv", delim = ",")

```

## The "problems"

You saw warning messages when reading in this dataset. We can see these with the `problems()` function from `readr`. 

If we scroll through we can see some interesting notes.

```{r}
p <-problems(ufo)
p %>% glimpse()
```

## Any unique problems?

```{r}
count(p, expected, actual)
```


## The "problems"

Go look at the raw data around these rows.
```{r, echo = FALSE}
knitr::include_graphics(here::here("lecture_notes", "media", "problems.png"))

```

```{r}
colnames(ufo)
```

## Reading in again

Now we have a chance to keep but clean these values!

```{r}
url <- "https://sisbid.github.io/Data-Wrangling/data/ufo/ufo_data_complete.csv"
ufo <-read_csv(url, col_types = cols(`duration (seconds)` = "c"))
```

## Look at the problems again

```{r}
p <- problems(ufo)

count(p, expected, actual)
```

## Drop the remaining shifted problematic rows for now
Multiply by negative one to drop the rows. Use the Slice function to "select" those rows based on the index. Need to offset for `-1` because `problems()` gives us the index row based on the raw data, not the read in data. We will multiple by negative one to select out those rows as well. 

```{r}
head(p, n = 2)
(pull(p, row) -1) %>% head()
((pull(p, row) -1) *-1) %>% head()
ufo_clean <- ufo %>% slice((pull(p, row)-1)*-1)
```


## Checking

```{r}
nrow(ufo) - nrow(ufo_clean)
count(p, expected, actual)
```

## Clean names with the `clean_names()` function from the `janitor` package

```{r}
colnames(ufo_clean)
ufo_clean <- clean_names(ufo_clean)
colnames(ufo_clean)
```

<!-- ## Let's just drop those problematic rows for now. -->

<!-- Though you would usually want to check them! -->



# Recoding Variables

## Exact Swaps - recode function

```
within mutate...
recode(variable, value_old = value_new,
           other_value_old = other_value_new)
```

```{r}
ufo_clean %>% 
  mutate(country = 
           recode(country, gb = "Great Britain")) %>% 
  glimpse()

```


## Exact Swaps - recode function


```{r}
ufo_clean %>% mutate(country = 
          recode(country, 
                 gb = "Great Britain",
                 us = "United States")) %>% 
  glimpse()

```



## How many countries?

```{r}
ufo_clean %>% count(country)
```

## `case_when()` regions to create a new variable based on conditions of other variables

```
case_when(test ~ value if test is true,
         test2 ~ vlue if test2 is true,
         TRUE ~ value if all above tests are not true) # defaults to NA
```

```{r}
ufo_clean <- ufo_clean %>% mutate( 
            region = case_when(
              country %in% c("us", "ca") ~ "North America",
              country %in% c("de") ~ "Europe",
              country %in% "gb" ~ "Great Britain",
              TRUE ~ "Other"
            ))
ufo_clean %>% select(country, region) %>% head()
```



## `case_when` - another example

The `TRUE` value can also just be the original values.

```{r}
ufo_clean %>% mutate(country = case_when(
                  country == "gb" ~ "Great Britain",
                  country == "us" ~"United States",
                  country == "au" ~ "Australia",
                  country == "DE" ~ "Germany",
                             TRUE ~ country))%>%
  glimpse()

```




## Strange country values


Sometimes `country` is `NA` even though `state` is known.
A conditional more flexible recoding would be helpful...


```{r}
head(ufo_clean)

```

## Deeper look

Looking at city... it seems like many of these are in fact in the US.

```{r}
ufo_clean %>% filter(state == "tx") %>% count(country, state)
ufo_clean %>% filter(state == "tx" & is.na(country)) %>% select(city)
```


## Checkin Utah as well

```{r}
ufo_clean %>% filter(state == "ut") %>% count(country, state)
ufo_clean %>% filter(state == "ut" & is.na(country))  %>% select(city)
```



## Get US States

```{r}
ufo_clean %>% filter(country == "us") %>% 
  count(state) %>% 
  pull(state)
US_states <- ufo_clean %>% 
  filter(country == "us") %>% 
  count(state) %>% 
  pull(state)

```

## Get Canada States
```{r}
ufo_clean %>% filter(country == "ca") %>% 
  count(state) %>% 
  pull(state)
CA_states <- ufo_clean %>% 
  filter(country == "ca") %>% 
  count(state) %>% 
  pull(state)

```

## Get Great Britan states

```{r}
ufo_clean %>% filter(country == "gb") %>% 
  count(state) %>% 
  pull(state)
GB_states <- ufo_clean %>% 
  filter(country == "gb") %>% 
  count(state) %>% 
  pull(state)

```
A small overlap with us states.



## Get DE states

```{r}
ufo_clean %>% filter(country == "de") %>% 
  count(state) %>% 
  pull(state)

```

## Get AU states

```{r}
ufo_clean %>% filter(country == "au") %>% 
  count(state) %>% 
  pull(state)
AU_states <- ufo_clean %>% 
  filter(country == "au") %>% 
  count(state) %>% 
  pull(state)

```

Some overlap with US states.


## Get just unique

```{r}
US_states <- US_states[!(US_states %in% AU_states)]
US_states <- US_states[!(US_states %in% GB_states)]
US_states <- US_states[!(US_states %in% CA_states)]

AU_states <- AU_states[!(AU_states %in% US_states)]
AU_states <- AU_states[!(AU_states %in% GB_states)]
AU_states <- AU_states[!(AU_states %in% CA_states)]

CA_states <- CA_states[!(CA_states %in% US_states)]
CA_states <- CA_states[!(CA_states %in% GB_states)]
CA_states <- CA_states[!(CA_states %in% CA_states)]

GB_states <- GB_states[!(GB_states %in% US_states)]
GB_states <- GB_states[!(GB_states%in% AU_states)]
GB_states <- GB_states[!(GB_states %in% CA_states)]
```

## How often do rows have a value for country but not the US?

```{r}
ufo_clean %>% 
  filter(country != "us" & !is.na(country)) %>% 
  count(country) 

```




## more complicated case_when

Let's make an assumption that if the state value is within the data as a state for a specific country that it comes from that country for the sake of illustration. 

```{r}
ufo_clean <- ufo_clean %>% mutate(prob_country = 
      case_when((is.na(country) & state %in% c(US_states)) ~ "United States",
                (is.na(country) & state %in% c(CA_states)) ~ "Canada",
                (is.na(country) & state %in% c(AU_states)) ~ "Australia",
                (is.na(country) & state %in% c(GB_states)) ~ "Great Britain",
                   TRUE ~ country))
```

## results

```{r}
count(ufo_clean, prob_country)
```


## results

Take a look at those NAs.

```{r}
ufo_clean %>% filter(is.na(prob_country))
```


## We could confirm with city info and latitude and longitude

```{r}
ufo_clean %>% filter(country == "de") %>% 
  pull(city)
```


## Even more specific

```{r}
ufo_clean <- ufo_clean %>% mutate(prob_country = 
      case_when(
      (is.na(country) & state %in% c(US_states))  | 
  country == "us" ~ "United States",
      (is.na(country) & state %in% c(CA_states))  | 
  country == "ca" ~ "Canada",
      (is.na(country) & state %in% c(AU_states))  | 
  country == "au" ~ "Australia",
      (is.na(country) & state %in% c(GB_states))  | 
  country == "gb" ~ "Great Britain",
       country == "de" ~ "Germany",
                   TRUE ~ country))

```

We would want to confirm what we recoded with the cities and latitude and longitude, especially to deal with the overlaps in the state lists. 

## Check counts

```{r}
ufo_clean %>% 
  count(country, prob_country)
```

## Summary

- `recode` makes exact swaps
- `case_when` can use conditionals, need to specify what value for if no conditions are met (can be the original value of a variable if we use the variable name).

## Lab

https://sisbid.github.io/Data-Wrangling/labs/data-cleaning-lab.Rmd



